\section{Similarity and Diagonalisation}

\begin{paracol}{2}

A matrix $A$ can in some cases be decomposed as $A = PBP^{-1}$ - with $B$ a diagonal or a rotation-scaling matrix. $A$ and $B$ share many properties, and in that sense are similar.

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    Two $n \times n$-matrices $A$ and $B$ are \textbf{similar} if there exists an invertible $n \times n$-matrix $P$ such that
    
    $$A \sim B \iff A = PBP^{-1} \iff AP = PB$$

    The transformation from $A$ to $P^{-1}AP$ is called a \textbf{similarity transformation}. \\

    The matrix $P$ depends on $A$ and $B$, and is not unique for a given pair of similar matrices $A$ and $B$.
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Definition};
\end{tikzpicture}

An example of a similarity transformation is diagonalisation: It gives a relation between a matrix and a diagonal matrix. That is convenient, because usually, a diagonal matrix is much easier to work with, e.g. to compute a high power of the matrix.

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    Let $A, B, C$ be $n \times n$ matrices. Then

    \begin{enumerate}
        \item $A \sim A$
        \item Symmetry: If $A \sim B$, then $B \sim A$.
        \item Transitivity: If $A \sim B$ and $B \sim C$, then $A \sim C$.
    \end{enumerate}
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    Let $A = PBP^{-1}$ with change-of-basis matrix $P = \begin{bmatrix}
        \mathbf{v}_1 & \mathbf{v}_2 & \dots \mathbf{v}_n
    \end{bmatrix}$. \\

    If $T$ is the linear transformation with standard matrix $A$ then $B$ is the matrix of $T$ with respect to the basis $\{ \mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n \}$:

    $$BP^{-1}\mathbf{x} = P^{-1}A\mathbf{x}$$
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    If $A \sim B$,

    $$A\mathbf{v} = \lambda\mathbf{v} \iff B(P^{-1}\mathbf{v}) = \lambda(P^{-1}\mathbf{v})$$

    That is, \\
    
    \begin{enumerate}
        \item $A$ and $B$ have the same eigenvalues. \\
        
        \item $\mathbf{v}$ is eigenvector of $A$ with eigenvalue $\lambda_i \iff P^{-1}\mathbf{v}$ is eigenvector of $B$ with same eigenvalue $\lambda_i$
        
        (note: $P^{-1}\mathbf{v} \neq \mathbf{0}$ because $P^{-1}$ is invertible). \\
        
        \item $A$ and $B$ have the same geometric multiplicity:

        $$\text{dim} E_{\lambda_i}(A) = \text{dim} E_{\lambda_i}(B)$$
    \end{enumerate}
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

\switchcolumn

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    If $A \sim B$,

    $$\text{det}(A - \lambda I) = \text{det}(B - \lambda I)$$

    That is, \\
    
    \begin{enumerate}
        \item $\text{det}(A) = \text{det}(B)$

        \item $A$ is invertible if and only if $B$ is invertible.

        \item $A$ and $B$ have the same rank. \\

        \item $A$ and $B$ have the same characteristic polynomial. \\

        \item the multiplicity of each shared root of that polynomial, i.e. the algebraic multiplicity, is the same for $A$ as for $B$.
    \end{enumerate}
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

\textbf{Proof}:

\vspace{-20pt}

$$A - \lambda I = PBP^{-1} - \lambda I = PBP^{-1} - \lambda PIP^{-1} = P(B - \lambda I)P^{-1}$$

\vspace{-30pt}

\begin{align*}
    \Rightarrow \quad & \text{det}(A - \lambda I) = \text{det}(P(B - \lambda I)P^{-1}) \\
    & = \text{det}(P) \text{det}(B - \lambda I) \text{det}(P^{-1}) = \text{det}(B - \lambda I)
\end{align*}

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    If a matrix is subjected to a similarity transformation then the eigenvalues and their multiplicities (algebraic and geometric) are preserved.
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

Hence, two $n \times n$-matrices $A$ and $B$ cannot be similar if

\begin{itemize}
    \item $A$ and $B$ do not have the same characteristic polynomial, or
    \item $A$ and $B$ have the same characteristic polynomial but for at least one of the shared eigenvalues the geometric multiplicities are not the same.
\end{itemize}

Similar matrices have the same eigenvalues with the same algebraic and geometric multiplicities.

\textit{Conversely, however, if two matrices have the same eigenvalues with the same algebraic and geometric multiplicities, they are not necessarily similar.}

\textbf{Example}: Both $A$ and $B$ have one eigenvalue $0$ with algebraic multiplicity equal to $4$ and geometric multiplicity equal to $2$.

$$A = \begin{bmatrix}
    0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 \\
    0 & 0 & 0 & 0
\end{bmatrix} \qquad B = \begin{bmatrix}
    0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 \\
    0 & 0 & 0 & 0
\end{bmatrix}$$

But there is no invertible matrix $P$ such that $A = PBP^{-1}$. ($AP = PB$ implies that the second column of $P$ is equal to the zero column, so $P$ cannot be invertible.)

\end{paracol}

\newpage

\subsection{Diagonalisation}

\begin{paracol}{2}

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    An $n \times n$ matrix $A$ is diagonalisable if there is a diagonal matrix $D$ such that $A$ is similar to $D$; that is, if there is an invertible $n \times n$ matrix $P$ such that

    $$A = P D P^{-1}$$
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Definition};
\end{tikzpicture}

\textbf{Application}: Calculating high powers of a matrix:

\begin{align*}
    A^k & = (P D P^{-1})^k \\
    & = P D P^{-1} P D P^{-1} \dots P D P^{-1} \\
    & = P D I D I \dots D P^{-1} \\
    & = P D^k P^{-1}
\end{align*}

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    Let $A$ be an $n \times n$-matrix. Then $A$ is diagonalisable if and only if $A$ has $n$ linearly independent eigenvectors. \\

    That is, there exist an invertible matrix $P$ and a diagonal matrix $D$ such that $A = P D P^{-1}$ if and only if the columns of $P$ are $n$ \textit{linearly independent eigenvectors} of $A$ and the diagonal entries of $D$ are the eigenvalues of $A$ corresponding to the eigenvectors in $P$ in the same order:

    $P = \begin{bmatrix}
        \mathbf{v}_1 & \mathbf{v}_2 & \dots & \mathbf{v}_n
    \end{bmatrix},
    D = \begin{bmatrix}
        \lambda_1 & 0 & \dots & 0 \\
        0 & \lambda_2 & \dots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \dots & \lambda_n
    \end{bmatrix}$
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

\textbf{Application}: Finding the standard matrix of a reflection:

Consider the line $L = \text{Span} \Big\{ \begin{bmatrix}
    2 \\ 1
\end{bmatrix} \Big\} \in \mathbb{R}^2$. Let $R_L$ be the standard matrix of reflection through $L$. From geometry, we know that $L$ is an eigenspace with eigenvalue $1$, and $L^\perp$ is an eigenspace with eigenvalue $-1$. In particular, $\begin{bmatrix}
    2 \\ 1
\end{bmatrix}$ and $\begin{bmatrix}
    -1 \\ 2
\end{bmatrix}$ are eigenvectors with eigenvalues $1$ and $-1$, respectively. Since they are linearly independent:

\vspace{-20pt}

\begin{align*}
    R_L & = P D P^{-1} \\
    & = \begin{bmatrix}
        2 & -1 \\
        1 & 2
    \end{bmatrix} \begin{bmatrix}
        1 & 0 \\
        0 & -1
    \end{bmatrix} \begin{bmatrix}
        2 & -1 \\
        1 & 2
    \end{bmatrix}^{-1} \\
    & = \begin{bmatrix}
        2 & -1 \\
        1 & 2
    \end{bmatrix} \begin{bmatrix}
        1 & 0 \\
        0 & -1
    \end{bmatrix} \frac{1}{5} \begin{bmatrix}
        2 & 1 \\
        -1 & 2
    \end{bmatrix} \\
    & = \frac{1}{5} \begin{bmatrix}
        3 & 4 \\
        4 & -3
    \end{bmatrix}
\end{align*}

\switchcolumn

\textbf{Application}: Discrete dynamical systems:

Consider two towns $A$ and $B$. At a certain point in time, town $A$ has $4,000$ inhabitants, and town $B$ has $5,000$. Every year, $5\%$ of the population of $A$ moves to $B$, and $10\%$ of the population of $B$ moves to $A$. What is the population distribution after $10$ years?

\begin{align*}
    \begin{bmatrix}
        p_{A, k} \\ p_{B, k}
    \end{bmatrix} & = \begin{bmatrix}
        0.95 & 0.1 \\
        0.05 & 0.9
    \end{bmatrix} \begin{bmatrix}
        4000 \\ 5000
    \end{bmatrix} \\
    & = P D^k P^{-1} \begin{bmatrix}
        4000 \\ 5000
    \end{bmatrix} \\
    & = \begin{bmatrix}
        2 & -1 \\
        1 & 1
    \end{bmatrix} \begin{bmatrix}
        1 & 0 \\
        0 & 0.85
    \end{bmatrix}^k \begin{bmatrix}
        2 & -1 \\
        1 & 1
    \end{bmatrix}^{-1} \begin{bmatrix}
        4000 \\ 5000
    \end{bmatrix} \\
    & = P D^k P^{-1} \begin{bmatrix}
        4000 \\ 5000
    \end{bmatrix} \\
    & = \begin{bmatrix}
        2 & -1 \\
        1 & 1
    \end{bmatrix} \begin{bmatrix}
        1 & 0 \\
        0 & 0.85
    \end{bmatrix}^k \frac{1}{3} \begin{bmatrix}
        1 & 1 \\
        -1 & 2
    \end{bmatrix} \begin{bmatrix}
        4000 \\ 5000
    \end{bmatrix} \\
    & = \frac{1}{3} \begin{bmatrix}
        2 + 0.85^k & 2 - 2 \cdot 0.85^k \\
        1 - 0.85^k & 1 + 2 \cdot 0.85^k
    \end{bmatrix} \begin{bmatrix}
        4000 \\ 5000
    \end{bmatrix}
\end{align*}

In the long run, the solution stabilises:

$$
\lim_{k \rightarrow \infty}{\begin{bmatrix}
    p_{A, k} \\ p_{B, k}
\end{bmatrix}} = \frac{1}{3} \begin{bmatrix}
    2 & 2 \\
    1 & 1
\end{bmatrix} \begin{bmatrix}
    p_{A, 0} \\ p_{B, 0}
\end{bmatrix} = \begin{bmatrix}
    \frac{2}{3} (p_{A, 0} + p_{B, 0}) \\
    \frac{1}{3} (p_{A, 0} + p_{B, 0})
\end{bmatrix}
$$

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    Let $A$ be an $n \times n$-matrix. If $A$ is diagonalisable, then: \\

    \begin{enumerate}
        \item There exists an \textbf{eigenbasis}, i.e. a set of $n$ linearly independent eigenvectors / $n$ distinct eigenvalues of $A$. \\
        \item The sum of the geometric multiplicities of the eigenvalues of $A$, i.e. the sum of the dimensions of the eigenspaces of $A$, is equal to $n$. (If it is less than $n$, there aren't enough eigenvectors for an $n$-dimensional eigenbasis.) \\
        \item For each eigenvalue of $A$, the algebraic multiplicity is equal to the geometric multiplicity. ($n \geq a.m. \geq g.m. \geq 1$, so $g.m. = n \Rightarrow a.m. = n = g.m.$)
    \end{enumerate}
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

It follows from statement $4$ that:

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    If all eigenvalues have $a.m. = 1$ (for a total of $n$), then $A$ is diagonalisable.
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Corollary};
\end{tikzpicture}

\end{paracol}

\subsection{Rotation-Scaling Matrices}

\begin{paracol}{2}

If $A = P D P^{-1}$ is a diagonalisable matrix with complex eigenvalues, then the matrices $P$ and $D$ necessarily have complex entries. \\

However, for $2 \times 2$-matrices  you can also make the decomposition $A = P C P^{-1}$ where $C$ is the so-called rotation-scaling matrix - the \textit{composition of a rotation matrix and a scaling matrix}.

\switchcolumn

\begin{tikzpicture}
\node [rounded-box] (box){\begin{minipage}{0.45\textwidth}
    Let $A$ be a real $2 \times 2$-matrix with eigenvalues $a \pm ib$, where $b \neq 0$ and $a, b \in \mathbb{R}$. Then there exists an invertible real matrix $P$ such that

    $$A = P \begin{bmatrix}
        a & -b \\
        b & a
    \end{bmatrix} P^{-1} \iff P = \begin{bmatrix}
        \text{Re } \mathbf{v} & \text{Im } \mathbf{v}
    \end{bmatrix}$$

    where $\mathbf{v}$ is an eigenvector of $A$ that belongs to the eigenvalue $a - ib$.
\end{minipage}};
\node[rounded-box-title, left=10pt] at (box.north east) {Theorem};
\end{tikzpicture}

\end{paracol}
