# Uncertainty

- Bayesian probability theory: modelling, inference, reasoning, decision making under uncertainty
- Graphical models: directed and undirected; Bayesian networks, Markov Networks and Factor Graphs
- Independence in graphical models
- Inference algorithms: singly-connected graphs, Hidden Markov Models, message passing, belief propagation
- Approximate Inference using Sampling.
- Learning: Parameter learning, structure learning
- Latent variable models, including mixture models and factor models.
- The Expectation-Maximisation (EM) algorithm.
- Time series, including hidden Markov models and state-space models.
- Combining logic with graphical models
- Applications

## References

Barber, D. (2012). Bayesian Reasoning and Machine Learning. Cambridge University Press. Retrieved from <http://www.cs.ucl.ac.uk/staff/d.barber/brml/>

Deisenroth, M. (2019). Probabilistic Inference [Course materials]. Imperial College London. Retrieved from <https://www.deisenroth.cc/teaching/2018-19/probabilistic-inference/>,

Gutmann, M. (2023). Probabilistic Modelling and Reasoning [Course materials]. The University of Edinburgh. Retrieved from <https://www.inf.ed.ac.uk/teaching/courses/pmr/22-23/>

Kuleshov, V., & Ermon, S. (2024). CS 228 - Probabilistic Graphical Models [Course materials]. Stanford University. Retrieved from <https://ermongroup.github.io/cs228-notes/>

Malan, D., & Yu, B. (2024). CS50â€™s Introduction to Artificial Intelligence with Python [Course materials]. Harvard OpenCourseWare. Retrieved from <https://cs50.harvard.edu/ai/2024/notes/2/>
